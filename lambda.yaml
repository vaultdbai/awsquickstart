AWSTemplateFormatVersion: 2010-09-09
Description: VaultDB Lambda funtion to execute Queries
Metadata:
  Author: VaultDB.ai
  Url: https://www.vaultdb.ai

Parameters:
  ApplicationName:
    Type: String
    AllowedPattern: "^[a-z][a-z0-9-]{0,48}[a-z0-9]$"
    Description: Enter the name of your application with no spaces.

Resources:
  ExecuteRole:
    Type: AWS::IAM::Role
    Properties:
      RoleName: !Join ["", [!Ref ApplicationName, "-execution-role"]]
      Tags:
        - Key: Purpose
          Value: "VaultDB"
      AssumeRolePolicyDocument:
        Version: "2012-10-17"
        Statement:
          - Effect: Allow
            Principal:
              Service:
                - lambda.amazonaws.com
            Action:
              - sts:AssumeRole
          - Effect: Allow
            Principal:
              Service:
                - ecs-tasks.amazonaws.com
            Action:
              - sts:AssumeRole
      Policies:
        - PolicyName:
            !Join ["", [!Ref ApplicationName, "-execution-service-policy"]]
          PolicyDocument:
            Version: "2012-10-17"
            Statement:
              - Effect: Allow
                Action:
                  - logs:CreateLogGroup
                Resource: "*"
              - Effect: Allow
                Action:
                  - logs:CreateLogStream
                  - logs:PutLogEvents
                Resource: "*"
              - Effect: Allow
                Action:
                  - s3:ListMultipartUploadParts
                  - s3:*Object
                  - s3:ListBucket
                Resource: "*"
              - Effect: Allow
                Action:
                  - elasticfilesystem:ClientMount
                  - elasticfilesystem:ClientWrite
                Resource: "*"
              - Effect: Allow
                Action:
                  - ec2:DescribeNetworkInterfaces
                  - ec2:CreateNetworkInterface
                  - ec2:DeleteNetworkInterface
                  - ec2:DescribeInstances
                  - ec2:AttachNetworkInterface
                Resource: "*"

  EFSAccessPointResource:
    Type: AWS::EFS::AccessPoint
    Properties:
      FileSystemId:
        Fn::ImportValue: !Sub "${ApplicationName}-EFSFileSystem"
      PosixUser:
        Uid: 1001
        Gid: 1001
      RootDirectory:
        CreationInfo:
          OwnerGid: 1001
          OwnerUid: 1001
          Permissions: 770
        Path: /commitlog

  VaultDBPythonLayer:
    Type: "AWS::Lambda::LayerVersion"
    Properties:
      LayerName: !Join ["", [!Ref ApplicationName, "-python-vaultdb-linux-layer"]]
      CompatibleRuntimes:
        - python3.12
      CompatibleArchitectures:
        - x86_64
      Content:
        S3Bucket:
          Fn::ImportValue: !Sub "${ApplicationName}-DataBucket"
        S3Key: "release/vaultdb312_layer.zip"

  ExecuteQueryFunction:
    Type: AWS::Lambda::Function
    Properties:
      Tags:
        - Key: Purpose
          Value: "VaultDB"
      Description: Execute Vaultdb SQL Qeries
      FunctionName: !Join ["", [!Ref ApplicationName, "-execute-query"]]
      Handler: index.lambda_handler
      MemorySize: 128
      Role: !GetAtt ExecuteRole.Arn
      Timeout: 240
      Layers:
        - !Ref VaultDBPythonLayer
      Runtime: python3.12
      Architectures:
        - x86_64
      Environment:
        Variables:
          application_name: !Sub "${ApplicationName}"
          aws_region: !Sub "${AWS::Region}"
          AWS_STS_REGIONAL_ENDPOINTS: "regional"
          commitlog_directory: "/mnt/commitlog"
          public_bucket:
            Fn::ImportValue: !Sub "${ApplicationName}-PublicBucket"
          data_store:
            Fn::ImportValue: !Sub "${ApplicationName}-DataBucket"
          user_pool_client_id:
            Fn::ImportValue: !Sub "${ApplicationName}-UserPoolClient"
      VpcConfig:
        SecurityGroupIds:
          - Fn::ImportValue: !Sub "${ApplicationName}-DataSecurityGroup"
        SubnetIds:
          - Fn::ImportValue: !Sub "${ApplicationName}-VPCPrivateSubnet"
      FileSystemConfigs:
        - Arn: !GetAtt EFSAccessPointResource.Arn
          LocalMountPath: /mnt/commitlog
      Code:
        ZipFile: |
          # Imports
          import os
          import logging
          import json
          import glob
          from json import JSONEncoder
          import duckdb

          keys = None

          def get_keys(key_store):
              import boto3
              global keys
              if keys:
                  return keys
              s3 = boto3.resource('s3')
              obj = s3.meta.client.get_object(Bucket=key_store, Key="jwks.json")
              keys = json.loads(obj['Body'].read())['keys']
              return keys

          # Set up the logger
          logger = logging.getLogger()
          logger.setLevel(logging.DEBUG) # Very verbose

          application_name = os.environ['application_name'] if "application_name" in os.environ else ""
          aws_region = os.environ['aws_region'] if "aws_region" in os.environ else "us-east-1"
          commitlog_directory = os.environ['commitlog_directory'] if "commitlog_directory" in os.environ else "/tmp"
          public_bucket = os.environ['public_bucket'] if "public_bucket" in os.environ else None
          data_store = os.environ['data_store'] if "data_store" in os.environ else None
          app_client_id = os.environ['user_pool_client_id'] if "user_pool_client_id" in os.environ else None

          get_keys(data_store) # Download Public Keys for token verification ahead as we need them for security

          def lambda_handler(event, context):
              token = event['token']    
              try:
                  verified_claims = verify_token(token, data_store, app_client_id)
                  preferred_role = str(verified_claims['cognito:preferred_role']).split(':role/')[-1]        
                  logger.info(f'preferred_role: {preferred_role}')
                  if application_name and preferred_role.startswith(application_name):
                      preferred_role = preferred_role[len(application_name)+1:]
                  if preferred_role.endswith('-AdminRole'):
                      preferred_role = preferred_role[:-10]
                  logger.info(f'role: {preferred_role}')

                  if 'RequestType' in event and event['RequestType'] == 'fetch-catalogues':
                      catalogues = glob.glob(f"{commitlog_directory}/*.db")
                      return {"result":"Success", "data":catalogues}
                  
                  repo = event['database']
                  logger.info(f'repo: {repo}')
                  catalog = event['catalog']
                  logger.info(f'catalog: {catalog}')
                  payload = event['payload']
                  logger.info(f'payload: {payload}')

                  connection = duckdb.connect(f"{commitlog_directory}/{catalog}.db", False, preferred_role, config={'allow_unsigned_extensions' : 'true'})
                  connection.execute(f"CREATE CONFIG REMOTE {data_store};")
                  connection.execute(f"CREATE CONFIG REMOTE_MERGE_PATH {public_bucket};")
                  df = connection.execute(payload).fetchdf()
                  return {"result":"Success", "data":df.to_json(orient="index")}
              except Exception as ex:
                  logger.error(ex)
                  return {"result":"Error", "message":str(ex)}

          def create_sample_database():
              test_db_path = f"{commitlog_directory}/{application_name}.db"
              if os.path.isfile(test_db_path):
                  return
              connection = duckdb.connect(test_db_path, False, "vaultdb")
              connection.execute('BEGIN TRANSACTION;')
              connection.execute(f"CREATE CONFIG REMOTE {data_store};")
              connection.execute(f"CREATE CONFIG REMOTE_MERGE_PATH {public_bucket};")
              connection.execute('CREATE TABLE tbl_ProductSales (ColID int, Product_Category  varchar(64), Product_Name  varchar(64), TotalSales int)')
              connection.execute('CREATE TABLE another_T (col1 INT, col2 INT, col3 INT, col4 INT, col5 INT, col6 INT, col7 INT, col8 INT)')
              connection.execute("INSERT INTO tbl_ProductSales VALUES (1,'Game','Mobo Game',200),(2,'Game','PKO Game',400),(3,'Fashion','Shirt',500),(4,'Fashion','Shorts',100);")
              connection.execute("INSERT INTO another_T VALUES (1,2,3,4,5,6,7,8), (11,22,33,44,55,66,77,88), (111,222,333,444,555,666,777,888), (1111,2222,3333,4444,5555,6666,7777,8888)")
              connection.execute('COMMIT;')

          create_sample_database() # Create Default Database for sample
                  
          def verify_token(token, key_store, app_client_id):
              import time
              from jose import jwk, jwt
              from jose.utils import base64url_decode
              # get the kid from the headers prior to verification
              headers = jwt.get_unverified_headers(token)
              kid = headers['kid']
              # search for the kid in the downloaded public keys
              key_index = -1
              for i in range(len(get_keys(key_store))):
                  if kid == keys[i]['kid']:
                      key_index = i
                      break
              if key_index == -1:
                  raise Exception('Public key not found in jwks.json')
              # construct the public key
              public_key = jwk.construct(keys[key_index])
              # get the last two sections of the token,
              # message and signature (encoded in base64)
              message, encoded_signature = str(token).rsplit('.', 1)
              # decode the signature
              decoded_signature = base64url_decode(encoded_signature.encode('utf-8'))
              # verify the signature
              if not public_key.verify(message.encode("utf8"), decoded_signature):
                  raise Exception('Signature verification failed')
              logger.info('Signature successfully verified')
              # since we passed the verification, we can now safely
              # use the unverified claims
              claims = jwt.get_unverified_claims(token)
              # additionally we can verify the token expiration
              if time.time() > claims['exp']:
                  raise Exception('Token is expired')
              # and the Audience  (use claims['client_id'] if verifying an access token)
              if claims['aud'] != app_client_id:
                  raise Exception('Token was not issued for this audience')
              # now we can use the claims
              logger.info(claims)
              return claims

Outputs:
  ExecuteRole:
    Description: VaultDB Execution Role that works on behalf of user
    Value: !GetAtt ExecuteRole.Arn
    Export:
      Name: !Sub ${ApplicationName}-ExecuteRole
  ExecuteQueryFunction:
    Description: VaultDB Execute Query Function
    Value: !Ref ExecuteQueryFunction
    Export:
      Name: !Sub ${ApplicationName}-ExecuteQueryFunction
  VaultDBPythonLayer:
    Description: VaultDB Python Layer
    Value: !Ref VaultDBPythonLayer
    Export:
      Name: !Sub ${ApplicationName}-VaultDBPythonLayer
  EFSAccessPointResource:
    Description: EFS Access Point Resource
    Value: !GetAtt EFSAccessPointResource.Arn
    Export:
      Name: !Sub ${ApplicationName}-EFSAccessPointResource
            
  CLI:
    Description: Use this command to invoke the Lambda function
    Value: !Sub |
      aws lambda invoke --function-name 'vaultdb-execute-query-${ApplicationName}' --payload 'SELECT CURRENT_CATALOG' lambda-output.txt --cli-binary-format raw-in-base64-out
