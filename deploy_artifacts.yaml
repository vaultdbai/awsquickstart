AWSTemplateFormatVersion: 2010-09-09
Description: VaultDB Lambda funtion to execute Queries
Metadata:
  Author: VaultDB.ai
  Url: https://vaultdb.ai
      
Parameters:
  ApplicationName:
    Type: String
    AllowedPattern: "^[a-z][a-z0-9-]{0,48}[a-z0-9]$"
    Description: Enter the name of your application with no spaces.

  SourceBucketName:
    Type: String
    Description: Vaultdb Artifact store.

  AdminEmail:
    Description: VaultDB Admin Email for default database user notifications
    Type: String
    AllowedPattern: '[^@]+@[^@]+\.[^@]+'
    Default: vaultdb@outlook.com

Resources:
  ExecuteUtilRole:
    Type: AWS::IAM::Role
    Properties:
      RoleName: !Join ['', ['vaultdb', '-execute-util-', !Ref ApplicationName]]
      Tags:
        - Key: Purpose
          Value: 'VaultDB'
      AssumeRolePolicyDocument:
        Version: '2012-10-17'
        Statement:
          - Effect: Allow
            Principal:
              Service:
                - lambda.amazonaws.com
            Action:
              - sts:AssumeRole
      Policies:
        - PolicyName: !Join ['', ['vaultdb', '-execute-util-policy-', !Ref ApplicationName]]
          PolicyDocument:
            Version: '2012-10-17'
            Statement:
              - Effect: Allow
                Action:
                  - logs:CreateLogGroup
                Resource: '*'
              - Effect: Allow
                Action:
                  - logs:CreateLogStream
                  - logs:PutLogEvents
                Resource: '*'
              - Effect: Allow
                Action:
                  - s3:ListMultipartUploadParts
                  - s3:*Object
                Resource: '*'

  DeploymentUtilFunction:
    Type: AWS::Lambda::Function
    Properties:
      Tags:
        - Key: Purpose
          Value: 'VaultDB'    
      Description: Execute Vaultdb SQL Qeries
      FunctionName: !Join ['', ['vaultdb', '-deployment-util-', !Ref ApplicationName]]
      Handler: index.lambda_handler
      MemorySize: 128
      Runtime: python3.8
      Role: !GetAtt ExecuteUtilRole.Arn
      Timeout: 60
      Environment:
        Variables:
          application_name: !Sub "${ApplicationName}"
          admin_email: !Sub "${AdminEmail}"
          aws_region: !Sub '${AWS::Region}'
          user_pool_id:
            Fn::ImportValue: !Sub "${ApplicationName}-UserPool"
          user_pool_client_id:
            Fn::ImportValue: !Sub "${ApplicationName}-UserPoolClient"
          identity_pool_id:
            Fn::ImportValue: !Sub "${ApplicationName}-IdentityPool"
          source_bucket: !Ref SourceBucketName
          destination_bucket:
            Fn::ImportValue: !Sub "${ApplicationName}-PublicBucket"
      Code:
        ZipFile: |
          import boto3
          import cfnresponse
          import botocore
          import json
          import os
          import logging

          logger = logging.getLogger()
          logger.setLevel(logging.INFO)

          s3 = boto3.resource('s3')
          source_bucket = os.environ['source_bucket']
          destination_bucket = os.environ['destination_bucket']

          def lambda_handler(event, context):
              try:
                  logger.info(f"event: {event}!")               
                  if event['RequestType'] == 'Delete':
                      for obj in s3.Bucket(destination_bucket).objects.filter():
                          s3.Object(destination_bucket, obj.key).delete()
                  else:
                      logger.info("New files uploaded to the source bucket.")
                      deploy_workbench(source_bucket, destination_bucket)
                      create_pool_cofig(destination_bucket)            
                      create_welcome_page(destination_bucket)
                  cfnresponse.send(event, context, cfnresponse.SUCCESS, {'result':'success'}, "CustomResourcePhysicalID")
              except Exception as e:
                  print(e)
                  cfnresponse.send(event, context, cfnresponse.FAILED, {'error':str(e)}, "CustomResourcePhysicalID")

          def create_welcome_page(destination_bucket):
              logger.info("Creating Welcome page!")                  
              application_name = os.environ['application_name']
              admin_email = os.environ['admin_email']
              response = s3.meta.client.get_object(Bucket=source_bucket, Key="welcome_template.html")
              welcomehtml = response['Body'].read().decode('utf-8')
              try:
                  import pystache
                  data = {
                  "name": application_name,
                  "email": admin_email
                  }
                  welcomehtml = pystache.render(welcomehtml, data)
              except:
                  logger.info("template error")    
                  
              welcomeobject = s3.Object(bucket_name=destination_bucket, key='index.html')
              welcomeobject.put(Body=welcomehtml)            
              logger.info("Created Welcome page!")                  

          def create_pool_cofig(destination_bucket):
              application_name = os.environ['application_name']
              aws_region = os.environ['aws_region']
              user_pool_id = os.environ['user_pool_id']
              user_pool_client_id = os.environ['user_pool_client_id']
              identity_pool_id = os.environ['identity_pool_id']

              logger.info(f"Creating workbench config file for pool {user_pool_id}!") 

              data_string = f"""window.APPLICATION_NAME = "{application_name}";
              window.REGION= "{aws_region}";
              window.USER_POOL_ID= "{user_pool_id}";
              window.USER_POOL_APP_CLIENT_ID= "{user_pool_client_id}";
              window.USER_IDENTITY_POOL_ID= "{identity_pool_id}";
              """

              object = s3.Object(bucket_name=destination_bucket, key='workbench/config.js')
              object.put(Body=data_string)            
              logger.info("Created workbench config file!")                  

          def deploy_workbench(source_bucket, destination_bucket):
              try:                  
                  for key in s3.meta.client.list_objects(Bucket=source_bucket, Prefix='workbench/')['Contents']:
                      file = key['Key']
                      if file=='workbench/':
                          continue
                      logger.info(f"Copying file {file}")
                      source = {'Bucket': source_bucket, 'Key': file}
                      response = s3.meta.client.copy(source, destination_bucket, file)
                  logger.info("Copied workbench files!")
              except botocore.exceptions.ClientError as error:
                  logger.error("There was an error copying the file to the destination bucket")
                  print('Error Message: {}'.format(error))        
              except botocore.exceptions.ParamValidationError as error:
                  logger.error("Missing required parameters while calling the API.")
                  print('Error Message: {}'.format(error))

        
  DeployInvoke:
    Type: AWS::CloudFormation::CustomResource
    DependsOn: DeploymentUtilFunction
    Properties:
      ServiceToken: !GetAtt DeploymentUtilFunction.Arn

Outputs:
  CLI:
    Description: Use this command to copy files
    Value: !Sub |
        aws lambda invoke --function-name 'vaultdb--deployment-util-${ApplicationName}' --payload '{ "Bucket": "test_bucket", "path": "tes" }' lambda-output.txt --cli-binary-format raw-in-base64-out
        